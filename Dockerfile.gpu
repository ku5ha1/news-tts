FROM nvidia/cuda:12.1.1-runtime-ubuntu22.04

WORKDIR /app

# System dependencies
RUN apt-get update && apt-get install -y \
    python3 python3-pip python3-venv \
    gcc g++ git curl libglib2.0-0 build-essential libsndfile1 \
    && rm -rf /var/lib/apt/lists/*

# Upgrade pip
RUN python3 -m pip install --upgrade pip setuptools wheel

# Copy requirements
COPY requirements.txt ./requirements.txt

# Install CUDA-enabled PyTorch first (cu121 wheels)
RUN pip install --no-cache-dir --index-url https://download.pytorch.org/whl/cu121 \
    torch==2.2.0+cu121 torchvision==0.17.0+cu121 torchaudio==2.2.0+cu121

# Create GPU requirements by filtering out CPU torch pins and find-links
RUN awk '!/^--find-links/ && !/^torch==/ && !/^torchvision==/ && !/^torchaudio==/' requirements.txt > requirements-gpu.txt

# Install remaining Python packages
RUN pip install --no-cache-dir --verbose -r requirements-gpu.txt

# Hugging Face caches inside /app for non-root user
ENV HF_HOME=/app/.cache/huggingface
ENV TRANSFORMERS_CACHE=/app/.cache/huggingface/transformers
ENV HF_HUB_DISABLE_PROGRESS_BARS=1
ENV TOKENIZERS_PARALLELISM=false
ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1
ENV PORT=8080

# Create cache directories and temp directories
RUN mkdir -p ${TRANSFORMERS_CACHE} && \
    mkdir -p /tmp /var/tmp /usr/tmp /app/tmp && \
    chmod 1777 /tmp /var/tmp /usr/tmp && \
    chmod 755 /app/tmp && \
    mkdir -p /app/.cache && chmod -R 755 /app/.cache

# Copy app code
COPY app/ ./app/

# Optional: pin a specific HF model revision at build time
ARG MODEL_REV
ENV MODEL_REV=${MODEL_REV}

# Preload HF model snapshots directly into the Transformers cache so runtime can load offline
RUN pip install --no-cache-dir huggingface-hub==0.23.4 && \
    HF_HUB_OFFLINE= TRANSFORMERS_OFFLINE= python3 - <<'PY'
from huggingface_hub import snapshot_download
import os
rev = os.getenv('MODEL_REV') or None
cache_dir = os.getenv('TRANSFORMERS_CACHE', '/app/.cache/huggingface/transformers')
print('Downloading snapshots to cache:', cache_dir)
snapshot_download('ai4bharat/indictrans2-en-indic-dist-200M', revision=rev, cache_dir=cache_dir, local_dir_use_symlinks=False)
snapshot_download('ai4bharat/indictrans2-indic-en-dist-200M', revision=rev, cache_dir=cache_dir, local_dir_use_symlinks=False)
print('Snapshots ready')
PY

# Entrypoint script
COPY entrypoint.sh /app/entrypoint.sh
RUN chmod +x /app/entrypoint.sh

# Create non-root user and set permissions
RUN useradd --create-home --shell /bin/bash app && \
    chown -R app:app /app
USER app

# Health check
HEALTHCHECK --interval=30s --timeout=60s --start-period=300s --retries=3 \
    CMD curl -f http://localhost:${PORT}/api/health || exit 1

EXPOSE ${PORT}

ENTRYPOINT ["/app/entrypoint.sh"]

# After baking models, enforce offline mode at runtime.
ENV HF_HUB_OFFLINE=1
ENV TRANSFORMERS_OFFLINE=1

