FROM nvidia/cuda:12.1.1-runtime-ubuntu22.04

WORKDIR /app

# System dependencies
RUN apt-get update && apt-get install -y \
    python3 python3-pip python3-venv \
    gcc g++ git curl libglib2.0-0 build-essential libsndfile1 \
    && rm -rf /var/lib/apt/lists/*

# Upgrade pip
RUN python3 -m pip install --upgrade pip setuptools wheel

# Copy requirements
COPY requirements.txt ./requirements.txt

# Install CUDA-enabled PyTorch first (cu121 wheels)
RUN pip install --no-cache-dir --index-url https://download.pytorch.org/whl/cu121 \
    torch==2.2.0+cu121 torchvision==0.17.0+cu121 torchaudio==2.2.0+cu121

# Create GPU requirements by filtering out CPU torch pins and find-links
RUN awk '!/^--find-links/ && !/^torch==/ && !/^torchvision==/ && !/^torchaudio==/' requirements.txt > requirements-gpu.txt

# Install remaining Python packages
RUN pip install --no-cache-dir --verbose -r requirements-gpu.txt

# Re-enforce CUDA Torch after all deps (prevents CPU wheel override)
RUN pip install --no-cache-dir --index-url https://download.pytorch.org/whl/cu121 \
    --upgrade --force-reinstall --no-deps \
    torch==2.2.0+cu121 torchvision==0.17.0+cu121 torchaudio==2.2.0+cu121

# Verify CUDA is available (avoid heredoc to be safe on different shells)
RUN python3 -c "import torch; print('torch cuda available:', torch.cuda.is_available()); print('torch version:', torch.__version__); import sys;\
    (print('cuda device count:', torch.cuda.device_count()) or print('cuda device name:', torch.cuda.get_device_name(0))) if torch.cuda.is_available() else None"

# Hugging Face caches inside /app for non-root user
ENV HF_HOME=/app/.cache/huggingface
ENV TRANSFORMERS_CACHE=/app/.cache/huggingface/transformers
ENV HF_HUB_DISABLE_PROGRESS_BARS=1
ENV TOKENIZERS_PARALLELISM=false
ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1
ENV PORT=8080

# Create cache directories and temp directories
RUN mkdir -p ${TRANSFORMERS_CACHE} && \
    mkdir -p /tmp /var/tmp /usr/tmp /app/tmp && \
    chmod 1777 /tmp /var/tmp /usr/tmp && \
    chmod 755 /app/tmp && \
    mkdir -p /app/.cache && chmod -R 755 /app/.cache && \
    mkdir -p /app/models

# Copy app code
COPY app/ ./app/

# Optional: pin a specific HF model revision at build time
ARG MODEL_REV
ENV MODEL_REV=${MODEL_REV}

# Preload HF model snapshots directly into stable local directories used by the app
RUN pip install --no-cache-dir huggingface-hub==0.23.4
COPY app/scripts/download_snapshots.py /app/scripts/download_snapshots.py
RUN HF_HUB_OFFLINE= TRANSFORMERS_OFFLINE= python3 /app/scripts/download_snapshots.py

# Entrypoint script
COPY entrypoint.sh /app/entrypoint.sh
RUN chmod +x /app/entrypoint.sh

# Create non-root user and set permissions
RUN useradd --create-home --shell /bin/bash app && \
    chown -R app:app /app
USER app

# Health check
HEALTHCHECK --interval=30s --timeout=60s --start-period=300s --retries=3 \
    CMD curl -f http://localhost:${PORT}/api/health || exit 1

EXPOSE ${PORT}

ENTRYPOINT ["/app/entrypoint.sh"]

# After baking models, enforce offline mode at runtime.
ENV HF_HUB_OFFLINE=1
ENV TRANSFORMERS_OFFLINE=1
